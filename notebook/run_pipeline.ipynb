{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SETUP PATH & IMPORT",
   "id": "c94c1a6195e76b4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-17T21:33:12.100230Z",
     "start_time": "2025-12-17T21:33:12.095789Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root\n",
    "PROJECT_ROOT = os.path.abspath(\"..\") if os.path.basename(os.getcwd()) == \"notebooks\" else os.getcwd()\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\UIT\\KLTN\\notebook\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "IMPORT PIPELINE",
   "id": "d4e6c1a3dcc8b1c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:33:15.407782Z",
     "start_time": "2025-12-17T21:33:12.105447Z"
    }
   },
   "cell_type": "code",
   "source": "from src.pipeline import run_pipeline\n",
   "id": "47795a6d63d62dc6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "KIỂM TRA DATASET",
   "id": "7d39e8ca2e785842"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:33:15.782067Z",
     "start_time": "2025-12-17T21:33:15.482295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_transaction.csv\n",
    "# fraud_dataset_v1.csv\n",
    "# fraud_dataset_v2.csv\n",
    "# creditcard.csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/fraud_dataset_v1.csv\")\n",
    "df.head(), df.shape\n",
    "\n"
   ],
   "id": "c2a117f904001154",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  WAERS BUKRS KTOSL BELNR BSCHL HKONT       DMBTR       WRBTR    label\n",
       " 0    C3   C31    C9   C92    A3    B1   280979.60        0.00  regular\n",
       " 1    C1   C18    C7   C76    A1    B2   129856.53   243343.00  regular\n",
       " 2    C1   C19    C2   C20    A1    B3   957463.97  3183838.41  regular\n",
       " 3    C4   C48    C9   C95    A2    B1  2681709.51    28778.00  regular\n",
       " 4    C5   C58    C1   C19    A3    B1   910514.49      346.00  regular,\n",
       " (533009, 9))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CHẠY PIPELINE",
   "id": "ded26f2ecf763f1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:50:56.942112Z",
     "start_time": "2025-12-17T21:33:15.801612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores, preds = run_pipeline(\n",
    "    csv_path=\"../data/raw/fraud_dataset_v1.csv\",\n",
    "    label_col=\"label\" # None, label, isFraud\n",
    ")\n"
   ],
   "id": "96d43d1c9c5bfc63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTO CONFIG: {'latent_dim': 4, 'epochs': 50, 'contamination': 0.01, 'use_global': True, 'use_local': True, 'use_sparse': True, 'early_stopping': True, 'patience': 5}\n",
      "Early stopping at epoch 44\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m scores, preds = \u001B[43mrun_pipeline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcsv_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m../data/raw/fraud_dataset_v1.csv\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabel_col\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mlabel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# None, label, isFraud\u001B[39;49;00m\n\u001B[32m      4\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\UIT\\KLTN\\src\\pipeline.py:99\u001B[39m, in \u001B[36mrun_pipeline\u001B[39m\u001B[34m(csv_path, label_col)\u001B[39m\n\u001B[32m     96\u001B[39m y_pred = (final_score > th).astype(\u001B[38;5;28mint\u001B[39m)\n\u001B[32m     98\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m99\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mMETRICS:\u001B[39m\u001B[33m\"\u001B[39m, \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_score\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    101\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m final_score, y_pred, latent, rec_err\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\UIT\\KLTN\\src\\evaluation.py:4\u001B[39m, in \u001B[36mevaluate\u001B[39m\u001B[34m(y_true, y_pred, scores)\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mevaluate\u001B[39m(y_true, y_pred, scores=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     precision = \u001B[43mprecision_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      5\u001B[39m     recall = recall_score(y_true, y_pred, zero_division=\u001B[32m0\u001B[39m)\n\u001B[32m      6\u001B[39m     f1 = f1_score(y_true, y_pred, zero_division=\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\UIT\\KLTN\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    213\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    214\u001B[39m         skip_parameter_validation=(\n\u001B[32m    215\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    216\u001B[39m         )\n\u001B[32m    217\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    224\u001B[39m     msg = re.sub(\n\u001B[32m    225\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    226\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    227\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    228\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\UIT\\KLTN\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2634\u001B[39m, in \u001B[36mprecision_score\u001B[39m\u001B[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[39m\n\u001B[32m   2464\u001B[39m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[32m   2465\u001B[39m     {\n\u001B[32m   2466\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33my_true\u001B[39m\u001B[33m\"\u001B[39m: [\u001B[33m\"\u001B[39m\u001B[33marray-like\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33msparse matrix\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m   (...)\u001B[39m\u001B[32m   2491\u001B[39m     zero_division=\u001B[33m\"\u001B[39m\u001B[33mwarn\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2492\u001B[39m ):\n\u001B[32m   2493\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute the precision.\u001B[39;00m\n\u001B[32m   2494\u001B[39m \n\u001B[32m   2495\u001B[39m \u001B[33;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2632\u001B[39m \u001B[33;03m    array([0.5, 1. , 1. ])\u001B[39;00m\n\u001B[32m   2633\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2634\u001B[39m     p, _, _, _ = \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2635\u001B[39m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2636\u001B[39m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2637\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2638\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2639\u001B[39m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m=\u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2640\u001B[39m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mprecision\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2641\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2642\u001B[39m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[43m=\u001B[49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2643\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2644\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m p\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\UIT\\KLTN\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    189\u001B[39m global_skip_validation = get_config()[\u001B[33m\"\u001B[39m\u001B[33mskip_parameter_validation\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    190\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[32m--> \u001B[39m\u001B[32m191\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    193\u001B[39m func_sig = signature(func)\n\u001B[32m    195\u001B[39m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\UIT\\KLTN\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2100\u001B[39m, in \u001B[36mprecision_recall_fscore_support\u001B[39m\u001B[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[39m\n\u001B[32m   1929\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[32m   1930\u001B[39m \n\u001B[32m   1931\u001B[39m \u001B[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2097\u001B[39m \u001B[33;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[32m   2098\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2099\u001B[39m _check_zero_division(zero_division)\n\u001B[32m-> \u001B[39m\u001B[32m2100\u001B[39m labels = \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2102\u001B[39m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[32m   2103\u001B[39m samplewise = average == \u001B[33m\"\u001B[39m\u001B[33msamples\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\UIT\\KLTN\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1881\u001B[39m, in \u001B[36m_check_set_wise_labels\u001B[39m\u001B[34m(y_true, y_pred, average, labels, pos_label)\u001B[39m\n\u001B[32m   1879\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m y_type == \u001B[33m\"\u001B[39m\u001B[33mmulticlass\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1880\u001B[39m             average_options.remove(\u001B[33m\"\u001B[39m\u001B[33msamples\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1881\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1882\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mTarget is \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m but average=\u001B[39m\u001B[33m'\u001B[39m\u001B[33mbinary\u001B[39m\u001B[33m'\u001B[39m\u001B[33m. Please \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1883\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mchoose another average setting, one of \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m % (y_type, average_options)\n\u001B[32m   1884\u001B[39m         )\n\u001B[32m   1885\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m pos_label \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[32m1\u001B[39m):\n\u001B[32m   1886\u001B[39m     warnings.warn(\n\u001B[32m   1887\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mNote that pos_label (set to \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m) is ignored when \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1888\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33maverage != \u001B[39m\u001B[33m'\u001B[39m\u001B[33mbinary\u001B[39m\u001B[33m'\u001B[39m\u001B[33m (got \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m). You may use \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1891\u001B[39m         \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[32m   1892\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "KIỂM TRA KẾT QUẢ",
   "id": "38236ee6ed5b2ae4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Total samples:\", len(preds))\n",
    "print(\"Detected anomalies:\", np.sum(preds))\n"
   ],
   "id": "78fa2fde8f9f6a0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "VẼ BIỂU ĐỒ",
   "id": "13d953587d867cba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(scores, bins=100)\n",
    "plt.title(\"Anomaly Score Distribution\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ],
   "id": "813a6337837cc17f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XEM TOP ANOMALIES",
   "id": "34d431a1f63ce28e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_result = df.copy()\n",
    "df_result[\"anomaly_score\"] = scores\n",
    "df_result[\"is_anomaly\"] = preds\n",
    "\n",
    "df_result.sort_values(\"anomaly_score\", ascending=False)\n"
   ],
   "id": "5fc0b6ee428df077",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
